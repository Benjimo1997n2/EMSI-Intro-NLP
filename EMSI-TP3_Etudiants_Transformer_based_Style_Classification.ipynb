{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Use a GPU (T4 is enough)\n",
        "**Goal**: The goal of this lab is to predict the style of a music just by analyzing (classification task) the title (and more for the last part). We will use and finetune Transformers architecture."
      ],
      "metadata": {
        "id": "uIjd4MRvvz1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Environment Setup and Installing Dependencies\n",
        "In Google Colab, you need to install the required libraries, primarily Hugging Face's Transformers library and PyTorch. You can do this with the following commands:"
      ],
      "metadata": {
        "id": "OcdPNz-vc0PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "BMAbt2tqVvyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then restart the environment if you are on colab"
      ],
      "metadata": {
        "id": "HUBuAu4mc2nZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preparing Your Dataset\n",
        "\n",
        "Since you're focusing on predicting playlist_genre based on track_name, you'll preprocess track_name as input and playlist_genre as labels. Here's how you can prepare your dataset:\n",
        "\n",
        "## Import Necessary Libraries:"
      ],
      "metadata": {
        "id": "vP7ergYmf3jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "L4uwB7PJvArb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess the Dataset:\n",
        "\n",
        "Read your dataset.\n",
        "Tokenize track_name.\n",
        "Convert playlist_genre into numerical labels."
      ],
      "metadata": {
        "id": "w0epJi7Sfzpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = # Your path\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Drop nan values\n",
        "# TODO\n",
        "\n",
        "# TODO: Analyse and plot data we will use (genre_label)\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = # TODO: Use the pretrained bert-base-uncased (from transformers)\n",
        "\n",
        "# Tokenize track names\n",
        "tokenized_data = # TODO: Use the tokenizer previously defined\n",
        "\n",
        "# Convert genres to categorical labels\n",
        "data['genre_label'] = # TODO: Use pandas.Categorial -> Labels to numbers\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, val_data = # TODO: Recommanded test_size=0.2\n"
      ],
      "metadata": {
        "id": "UVeix_8C75u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Custom Dataset Class:\n",
        "For use with PyTorch, you need to create a custom dataset class."
      ],
      "metadata": {
        "id": "MJ7JNA8kfwsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset  # Import the Dataset class specifically\n",
        "\n",
        "# Classe TracksDataset pour stocker et fournir des données musicales tokenisées et leurs labels pour l'entraînement de modèles avec PyTorch.\n",
        "class TracksDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Example of how to tokenize and encode the track names\n",
        "def encode_tracks(track_names):\n",
        "    return tokenizer(track_names, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Encode your data\n",
        "encoded_train_tracks = # TODO: Use the previously defined function and the feature 'track_name'\n",
        "encoded_val_tracks = # TODO: Same\n",
        "\n",
        "# Assuming genre labels are categorical and need to be converted to numerical labels\n",
        "# Example: using LabelEncoder from sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_data['genre_label'])\n",
        "val_labels = label_encoder.transform(val_data['genre_label'])\n",
        "\n",
        "# Now create your dataset using the encoded tracks and numerical labels\n",
        "train_dataset = # TODO: Use the previously created class\n",
        "val_dataset = # TODO: Same"
      ],
      "metadata": {
        "id": "SNogknjadUk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Data Loaders:\n",
        "You need data loaders to efficiently feed data to the model during training."
      ],
      "metadata": {
        "id": "pVAktsM-fnny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = # TODO\n",
        "val_loader = # TODO"
      ],
      "metadata": {
        "id": "h3Lijc_yfHNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Choose the Appropriate Model Architecture\n",
        "For a classification task, you'll use a BERT model specifically designed for sequence classification. Hugging Face provides a model called BertForSequenceClassification that is suitable for this purpose.\n",
        "\n",
        "First, import the necessary classes:"
      ],
      "metadata": {
        "id": "Gg76Y7u1fcK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW"
      ],
      "metadata": {
        "id": "GzM0yg8Kfgps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, initialize the BERT model for sequence classification:"
      ],
      "metadata": {
        "id": "aeSjxBA5fgB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classification labels: the number of genres in your dataset\n",
        "num_labels = # TODO\n",
        "\n",
        "# Load pre-trained BERT model for sequence classification\n",
        "model = # TODO (Tips, we are doing SequenceClassification)"
      ],
      "metadata": {
        "id": "8kWjRbQqfjil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Customize the Model’s Head\n",
        "In BertForSequenceClassification, the model's head is already designed for a classification task. It adds a fully connected layer on top of the pooled output, specifically for the purpose of classification. This means you don't need to manually customize the head for a basic classification task, as it's already set up for you.\n",
        "\n",
        "If you want to further customize this layer or add additional layers, you can modify the BertForSequenceClassification class, but for most standard classification tasks, this isn't necessary.\n",
        "\n",
        "Remember to move the model to the GPU if you're using one, to speed up training:"
      ],
      "metadata": {
        "id": "FB4ZOl0LgABS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Check if a GPU is available and if not, use a CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the specified device\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "R8mo1o1if_Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define Hyperparameters\n",
        "Before training, you need to set various hyperparameters for the training process. These include the learning rate, number of epochs, and the optimizer. Here's how you can do it:"
      ],
      "metadata": {
        "id": "Jt0Tpl8xgUuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Hyperparameters\n",
        "learning_rate = # TODO\n",
        "epochs = # TODO\n",
        "\n",
        "# Use AdamW optimizer - it's a version of Adam with a different weight decay\n",
        "optimizer = # TODO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIh255VRgWpd",
        "outputId": "c8704f17-a1d6-4c4f-8347-8458336517f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the learning rate scheduler, you can use a scheduler that has a warm-up period and then linearly decays the learning rate:"
      ],
      "metadata": {
        "id": "OO7utH2MgapN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0, # Default value\n",
        "                                            num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "vffwY4ehgcIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Training the Model\n",
        "Now, you can train the model. This involves multiple epochs where each epoch consists of a training phase followed by a validation phase."
      ],
      "metadata": {
        "id": "MUnGcWH3gfHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to calculate the accuracy of predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Move the model to the GPU\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['labels'].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
        "    print(f'Accuracy: {avg_val_accuracy}')\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "ZEMAzj1YghNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Evaluation\n",
        "After training your model, you should evaluate its performance on a test set (or validation set, if a separate test set isn't available). Evaluation helps you understand how well your model generalizes to unseen data. Here's a basic framework for evaluating your model:"
      ],
      "metadata": {
        "id": "_g_VvQUVsNLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_loader:\n",
        "        # Move tensors to the GPU\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "        true_labels.extend(label_ids.flatten())\n",
        "\n",
        "\n",
        "    print(classification_report(true_labels, predictions, target_names=data['playlist_genre'].unique()))\n",
        "\n",
        "evaluate(model, val_loader, device)\n"
      ],
      "metadata": {
        "id": "EN0VAFaYsKOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Inference Function\n",
        "To let users try out the model with their own input, you can create an inference function. This function will take a track name as input, process it, and then use the model to predict the genre."
      ],
      "metadata": {
        "id": "bzDA--CysQiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_genre(track_name, model, tokenizer, device):\n",
        "    # TODO: Use the eval mode of the model\n",
        "    # TODO: Tokenize your input\n",
        "    # TODO: Put the input_ids and attention_mask on the GPU (.to(device))\n",
        "    # TODO: Make the prediction\n",
        "    # TODO: Map the prediction with labels\n",
        "    # TODO: Return the predicted genre\n",
        "    return predicted_genre\n",
        "\n",
        "# Example Usage\n",
        "track_name = \"All the Day (Don Rokoko Remix)\"\n",
        "predicted_genre = predict_genre(track_name, model, tokenizer, device)\n",
        "print(f\"Predicted Genre: {predicted_genre}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExgkbJzksQPR",
        "outputId": "68a92cbf-d500-4fd5-ec74-214db4c4b975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Genre: pop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Enhanced Finetuning\n",
        "Here, the goal is to redo all the steps but with differents features (adding the artist name, the release date, ...) and improve the result."
      ],
      "metadata": {
        "id": "FSD2Bg_tUiH_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYyHRtJ1VtGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}